# -*- coding: utf-8 -*-
"""Yolov11 face detection SCFace dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/161gBnnu6xvJ6QIkjkvIjwCXKTPrCbLEr

Dataset: https://www.kaggle.com/datasets/adilshamim8/face-detection

# STEP 1: Setup and Installation
"""
# Import libraries
import os
import shutil
import yaml
from pathlib import Path
import sys

# Use the directory containing this script as the project root (dataset and yolo files are here)
SCRIPT_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(SCRIPT_DIR))

from yolo_interface import YOLO
import cv2

from IPython.display import Image, display
_has_display = True

"""# STEP 2: Dataset Preparation"""

# Dataset and working directory are in the same folder as this script
WORK_DIR = SCRIPT_DIR
DATASET_PATH = WORK_DIR / 'dataset'

if not DATASET_PATH.exists():
    print(f"Dataset not found at {DATASET_PATH}. Please ensure the 'dataset' folder is here.")
    sys.exit(1)
print(f"Using dataset at: {DATASET_PATH}")

"""# STEP 3: Convert CSV Annotations to YOLO Format

"""

"""
This dataset has:
- train/, valid/, test/ folders with images
- _annotations.csv in each folder with bbox coordinates
- CSV format: filename, width, height, class, xmin, ymin, xmax, ymax

YOLO format needs:
- class x_center y_center width height (all normalized 0-1)
"""

import pandas as pd

def csv_to_yolo_format(xmin, ymin, xmax, ymax, img_width, img_height):
    """
    Convert CSV bbox (xmin, ymin, xmax, ymax) to YOLO format
    YOLO format: class x_center y_center width height (normalized)
    """
    # Calculate center coordinates and dimensions
    x_center = (xmin + xmax) / 2.0
    y_center = (ymin + ymax) / 2.0
    width = xmax - xmin
    height = ymax - ymin

    # Normalize by image dimensions
    x_center /= img_width
    y_center /= img_height
    width /= img_width
    height /= img_height

    return x_center, y_center, width, height

def convert_dataset_to_yolo():
    """
    Convert the face detection dataset to YOLO format
    """
    # Create directory structure
    dirs = ['images/train', 'images/val', 'images/test',
            'labels/train', 'labels/val', 'labels/test']
    for d in dirs:
        os.makedirs(f'{WORK_DIR}/{d}', exist_ok=True)

    # Process each split (train, valid, test)
    splits = {
        'train': 'train',
        'valid': 'val',  # Rename 'valid' to 'val' for YOLO
        'test': 'test'
    }

    for source_split, target_split in splits.items():
        source_dir = f'{WORK_DIR}/dataset/{source_split}/{source_split}'
        csv_path = f'{source_dir}/_annotations.csv'

        if not os.path.exists(csv_path):
            print(f"⚠️ Warning: {csv_path} not found, skipping {source_split}")
            continue

        print(f"\nProcessing {source_split} split...")

        # Read CSV annotations
        df = pd.read_csv(csv_path)
        print(f"  Found {len(df)} annotations for {df['filename'].nunique()} images")

        # Group by filename (multiple faces per image)
        grouped = df.groupby('filename')

        processed_images = 0
        processed_annotations = 0

        for filename, group in grouped:
            # Copy image
            src_img = f'{source_dir}/{filename}'
            dst_img = f'{WORK_DIR}/images/{target_split}/{filename}'

            if os.path.exists(src_img):
                shutil.copy(src_img, dst_img)
                processed_images += 1

                # Create YOLO label file
                label_filename = os.path.splitext(filename)[0] + '.txt'
                label_path = f'{WORK_DIR}/labels/{target_split}/{label_filename}'

                with open(label_path, 'w') as f:
                    for _, row in group.iterrows():
                        # Convert to YOLO format
                        x_center, y_center, width, height = csv_to_yolo_format(
                            row['xmin'], row['ymin'], row['xmax'], row['ymax'],
                            row['width'], row['height']
                        )

                        # Write: class_id x_center y_center width height
                        # class_id = 0 for face (single class)
                        f.write(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
                        processed_annotations += 1
            else:
                print(f"  ⚠️ Image not found: {filename}")

        print(f"  ✓ Processed {processed_images} images with {processed_annotations} face annotations")

    print("\n" + "="*60)
    print("Dataset conversion complete!")
    print("="*60)

# Run conversion
convert_dataset_to_yolo()

"""# STEP 5: Create data.yaml Configuration File

"""

data_yaml = {
    'path': str(WORK_DIR),
    'train': 'images/train',
    'val': 'images/val',
    'test': 'images/test',  # Added test set
    'nc': 1,  # number of classes
    'names': ['face']  # class names
}

with open(f'{WORK_DIR}/data.yaml', 'w') as f:
    yaml.dump(data_yaml, f, default_flow_style=False)

print("\ndata.yaml created:")
print(yaml.dump(data_yaml, default_flow_style=False))

"""# STEP 6: Verify Dataset

"""

def verify_dataset():
    """Check dataset integrity"""
    train_images = len(os.listdir(f'{WORK_DIR}/images/train'))
    train_labels = len(os.listdir(f'{WORK_DIR}/labels/train'))
    val_images = len(os.listdir(f'{WORK_DIR}/images/val'))
    val_labels = len(os.listdir(f'{WORK_DIR}/labels/val'))
    test_images = len(os.listdir(f'{WORK_DIR}/images/test'))
    test_labels = len(os.listdir(f'{WORK_DIR}/labels/test'))

    print("\nDataset Summary:")
    print(f"Train - Images: {train_images}, Labels: {train_labels}")
    print(f"Val   - Images: {val_images}, Labels: {val_labels}")
    print(f"Test  - Images: {test_images}, Labels: {test_labels}")

    # Sample a label file to verify format
    if train_labels > 0:
        sample_label = os.listdir(f'{WORK_DIR}/labels/train')[0]
        print(f"\nSample label file ({sample_label}):")
        with open(f'{WORK_DIR}/labels/train/{sample_label}', 'r') as f:
            lines = f.readlines()[:3]  # Show first 3 annotations
            for line in lines:
                print(f"  {line.strip()}")
            if len(f.readlines()) > 3:
                print(f"  ... and more")

    if train_images == 0 or val_images == 0:
        print("\n⚠️ WARNING: No images found! Please check dataset organization.")
    elif train_images != train_labels or val_images != val_labels:
        print("\n⚠️ WARNING: Mismatch between images and labels!")
    else:
        print("\n✓ Dataset looks good!")

verify_dataset()

"""# STEP 7: Initialize YOLOv11 Model

"""

if __name__ == '__main__':

    # Load a pretrained YOLOv11 model (nano, small, medium, large, or extra-large)
    model = YOLO('yolo11n.pt')  # 'n' for nano (fastest), 's', 'm', 'l', 'x' for larger models

    print("\nModel loaded successfully!")

    """# STEP 8: Train the Model

    """

    print("\nStarting training...")

    # Training parameters
    results = model.train(
        data=str(WORK_DIR / 'data.yaml'),
        epochs=10,                # Number of training epochs
        imgsz=640,                 # Image size
        batch=16,                  # Batch size (reduce if out of memory)
        device=0,                  # Use GPU 0 (use 'cpu' if no GPU)
        workers=2,                 # Number of workers
        project=str(WORK_DIR),     # Save runs in script directory
        name='yolov11_face',       # Experiment name
        patience=20,               # Early stopping patience
        save=True,                 # Save checkpoints
        plots=True,                # Create plots
        # Augmentation parameters
        hsv_h=0.015,              # HSV-Hue augmentation
        hsv_s=0.7,                # HSV-Saturation augmentation
        hsv_v=0.4,                # HSV-Value augmentation
        degrees=0.0,              # Rotation (+/- deg)
        translate=0.1,            # Translation (+/- fraction)
        scale=0.5,                # Scale (+/- gain)
        flipud=0.0,               # Flip up-down probability
        fliplr=0.5,               # Flip left-right probability
        mosaic=1.0,               # Mosaic augmentation probability
    )

    print("\nTraining complete!")

    """# STEP 9: Evaluate the Model

    """

    # Load the best model
    best_model = YOLO(str(WORK_DIR / 'yolov11_face' / 'weights' / 'best.pt'))

    # Validate
    metrics = best_model.val()

    print("\nValidation Metrics:")
    print(f"mAP50: {metrics.box.map50:.4f}")
    print(f"mAP50-95: {metrics.box.map:.4f}")
    print(f"Precision: {metrics.box.mp:.4f}")
    print(f"Recall: {metrics.box.mr:.4f}")

    """# STEP 10: Test on Sample Images

    """

    # Test on validation images
    import glob
    from PIL import Image as PILImage

    val_images = glob.glob(f'{WORK_DIR}/images/val/*.jpg')[:5]

    print("\nRunning inference on sample images...")

    os.makedirs(WORK_DIR / 'sample_outputs', exist_ok=True)
    for img_path in val_images:
        results = best_model(img_path)

        # Display or save results
        for r in results:
            im_array = r.plot()  # plot a BGR numpy array of predictions
            im = PILImage.fromarray(im_array[..., ::-1])  # RGB PIL image
            if _has_display:
                display(im)
            else:
                out_path = WORK_DIR / 'sample_outputs' / Path(img_path).name
                im.save(out_path)
                print(f"Saved: {out_path}")

    """# STEP 11: Export Model

    """

    # Export to different formats
    print("\nExporting model...")

    # Export to ONNX (for deployment)
    best_model.export(format='onnx')

    # Export to TensorRT (for NVIDIA devices)
    # best_model.export(format='engine')

    # Export to TFLite (for mobile)
    # best_model.export(format='tflite')

    print("\n✓ Model exported successfully!")

    """# STEP 12: Save Model Locally

    """

    # Copy best model to a local folder (same directory as script)
    output_dir = WORK_DIR / 'saved_model'
    output_dir.mkdir(parents=True, exist_ok=True)

    weights_dir = WORK_DIR / 'yolov11_face' / 'weights'
    for name in ('best.pt', 'last.pt'):
        src = weights_dir / name
        if src.exists():
            shutil.copy(src, output_dir / name)

    print(f"\n✓ Models saved to: {output_dir}")